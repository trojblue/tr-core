{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m llava.serve.controller --host 0.0.0.0 --port 10000\n",
    "\n",
    "\n",
    "# python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path /rmt/quail/captioner-1.4-llava-v1.6-llama3.1-CLIP-8b-ft-1\n",
    "\n",
    "\n",
    "# python -m llava.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path /rmt/quail/captioner-1.3-llava-v1.6-llama3-8b-ft-1\n",
    "\n",
    "# python -m llava.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 17:51:18,997 [INFO] UniLogger: UniLoader.loads: .json LOADED from \"/rmt/yada/dev/tr-core/notebooks/vpred_api_default_workflow_api.json\" in 0.00s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "class WorkflowModifier:\n",
    "    def _create_tag_mapping(self, api_workflow: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Creates a mapping between tags and their corresponding node IDs.\"\"\"\n",
    "        tag_mapping = {}\n",
    "        for node_id, node_data in api_workflow.items():\n",
    "            if node_data['class_type'] == 'TaggedAny':\n",
    "                tag = node_data['inputs'].get('tag')\n",
    "                if tag:\n",
    "                    tag_mapping[tag] = node_id\n",
    "        return tag_mapping\n",
    "\n",
    "    def get_default_values(self, api_workflow: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Returns a dictionary of modifiable values in the overrides format.\"\"\"\n",
    "        tag_mapping = self._create_tag_mapping(api_workflow)\n",
    "        modifiable_values = {}\n",
    "        for tag, node_id in tag_mapping.items():\n",
    "            content = api_workflow[node_id]['inputs'].get('content')\n",
    "            if content:\n",
    "                modifiable_values[tag] = content\n",
    "        return modifiable_values\n",
    "\n",
    "    def modify_workflow(self, api_workflow: Dict[str, Any], overrides: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Modifies the workflow using the given overrides.\"\"\"\n",
    "        tag_mapping = self._create_tag_mapping(api_workflow)\n",
    "        for key, value in overrides.items():\n",
    "            if key in tag_mapping:\n",
    "                node_id = tag_mapping[key]\n",
    "                # Update the 'content' field in the corresponding node\n",
    "                api_workflow[node_id]['inputs']['content'] = str(value).strip()\n",
    "        return api_workflow\n",
    "\n",
    "    def __call__(self, api_workflow: Dict[str, Any], overrides: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Allows the class instance to be called directly to modify the workflow.\"\"\"\n",
    "        return self.modify_workflow(api_workflow, overrides)\n",
    "\n",
    "\n",
    "\n",
    "import unibox as ub\n",
    "\n",
    "wf = ub.loads(\"/rmt/yada/dev/tr-core/notebooks/vpred_api_default_workflow_api.json\")\n",
    "        \n",
    "\n",
    "overrides = {\n",
    "    'api_steps': 28,\n",
    "    'api_positive': '1girl, long hair, black hair'\n",
    "}\n",
    "\n",
    "\n",
    "modifier = WorkflowModifier()\n",
    "\n",
    "# Example usage\n",
    "res = modifier(wf, overrides)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_flow.utils.run_comfy_api import WorkflowExecutor\n",
    "\n",
    "executor = WorkflowExecutor()\n",
    "res = executor.run_workflow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Iterator, Tuple\n",
    "\n",
    "class Workflow:\n",
    "    def __init__(self, raw_json: Dict[str, Any]):\n",
    "        self.raw_json = raw_json\n",
    "        self._modifiable_keys = self._extract_modifiable_keys()\n",
    "\n",
    "    def _extract_modifiable_keys(self) -> Dict[str, Tuple[str, Any]]:\n",
    "        \"\"\"Extracts and returns a dictionary of modifiable keys and their content.\"\"\"\n",
    "        modifiable_keys = {}\n",
    "        for node_id, node_data in self.raw_json.items():\n",
    "            if node_data['class_type'] == 'TaggedAny':\n",
    "                tag = node_data['inputs'].get('tag')\n",
    "                content = node_data['inputs'].get('content')\n",
    "                if tag and content:\n",
    "                    modifiable_keys[tag] = (node_id, content)\n",
    "        return modifiable_keys\n",
    "\n",
    "    def get_modifiable_keys(self) -> Dict[str, Any]:\n",
    "        \"\"\"Returns a dictionary of modifiable keys and their content.\"\"\"\n",
    "        return {key: value[1] for key, value in self._modifiable_keys.items()}\n",
    "\n",
    "    def update_modifiable_keys(self, overrides: Dict[str, Any]) -> None:\n",
    "        \"\"\"Updates the modifiable keys using the given overrides.\"\"\"\n",
    "        for key, value in overrides.items():\n",
    "            if key in self._modifiable_keys:\n",
    "                node_id, _ = self._modifiable_keys[key]\n",
    "                self.raw_json[node_id]['inputs']['content'] = value\n",
    "                self._modifiable_keys[key] = (node_id, value)\n",
    "\n",
    "    def export(self) -> Dict[str, Any]:\n",
    "        \"\"\"Exports the workflow as a dictionary.\"\"\"\n",
    "        return self.raw_json\n",
    "\n",
    "    def __getitem__(self, key: str) -> Any:\n",
    "        \"\"\"Allows direct access to raw_json like a dictionary.\"\"\"\n",
    "        return self.raw_json[key]\n",
    "\n",
    "    def __setitem__(self, key: str, value: Any) -> None:\n",
    "        \"\"\"Allows direct setting of items in raw_json like a dictionary.\"\"\"\n",
    "        self.raw_json[key] = value\n",
    "        self._modifiable_keys = self._extract_modifiable_keys()  # Refresh modifiable keys\n",
    "\n",
    "    def __delitem__(self, key: str) -> None:\n",
    "        \"\"\"Allows direct deletion of items in raw_json like a dictionary.\"\"\"\n",
    "        del self.raw_json[key]\n",
    "        self._modifiable_keys = self._extract_modifiable_keys()  # Refresh modifiable keys\n",
    "\n",
    "    def __iter__(self) -> Iterator[Tuple[str, Any]]:\n",
    "        \"\"\"Allows iteration over the raw_json as key-value pairs.\"\"\"\n",
    "        return iter(self.raw_json.items())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the length of the raw_json.\"\"\"\n",
    "        return len(self.raw_json)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Custom representation for the Workflow class.\"\"\"\n",
    "        return f\"<Workflow with {len(self.raw_json)} nodes> | modifiable keys: {list(self._modifiable_keys.keys())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': {'seed': 764222903364357, 'steps': ['29', 0], 'cfg': ['22', 0], 'sampler_name': ['23', 0], 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['26', 0], 'positive': ['27', 0], 'negative': ['28', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}\n"
     ]
    }
   ],
   "source": [
    "workflow = Workflow(wf)\n",
    "\n",
    "# Access the workflow like a normal dictionary\n",
    "print(workflow['3'])  # Accessing a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api_batchsize': '2',\n",
       " 'api_positive': 'new positive content',\n",
       " 'api_negative': 'new negative content',\n",
       " 'api_width': '896\\n',\n",
       " 'api_height': '1152',\n",
       " 'api_cfg': '0.9',\n",
       " 'api_sampler_name': 'euler_cfg_pp',\n",
       " 'api_steps': 28}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Special handling of modifiable keys\n",
    "modifiable_keys = workflow.get_modifiable_keys()\n",
    "modifiable_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': {'inputs': {'seed': 764222903364357, 'steps': ['29', 0], 'cfg': ['22', 0], 'sampler_name': ['23', 0], 'scheduler': 'sgm_uniform', 'denoise': 1, 'model': ['26', 0], 'positive': ['27', 0], 'negative': ['28', 0], 'latent_image': ['5', 0]}, 'class_type': 'KSampler', '_meta': {'title': 'KSampler'}}, '4': {'inputs': {'ckpt_name': 'yada_checkpoints/qft_v5c-c53_v5c-logfav-9.6_60k_cont2/checkpoint-e35_s10000.safetensors'}, 'class_type': 'CheckpointLoaderSimple', '_meta': {'title': 'Load Checkpoint'}}, '5': {'inputs': {'width': ['18', 0], 'height': ['19', 0], 'batch_size': ['10', 0]}, 'class_type': 'EmptyLatentImage', '_meta': {'title': 'Empty Latent Image'}}, '8': {'inputs': {'samples': ['3', 0], 'vae': ['4', 2]}, 'class_type': 'VAEDecode', '_meta': {'title': 'VAE Decode'}}, '9': {'inputs': {'filename_prefix': 'ComfyUI', 'images': ['8', 0]}, 'class_type': 'SaveImage', '_meta': {'title': 'Save Image'}}, '10': {'inputs': {'tag': 'api_batchsize', 'enforce_type': 'auto', 'content': '2'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '11': {'inputs': {'sampling': 'v_prediction', 'zsnr': True, 'model': ['4', 0]}, 'class_type': 'ModelSamplingDiscrete', '_meta': {'title': 'ModelSamplingDiscrete'}}, '12': {'inputs': {'tag': 'api_positive', 'enforce_type': 'auto', 'content': 'new positive content'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '14': {'inputs': {'tag': 'api_negative', 'enforce_type': 'auto', 'content': 'new negative content'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '15': {'inputs': {'multiplier': 0.7, 'model': ['11', 0]}, 'class_type': 'RescaleCFG', '_meta': {'title': 'RescaleCFG'}}, '18': {'inputs': {'tag': 'api_width', 'enforce_type': 'auto', 'content': '896\\n'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '19': {'inputs': {'tag': 'api_height', 'enforce_type': 'auto', 'content': '1152'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '22': {'inputs': {'tag': 'api_cfg', 'enforce_type': 'auto', 'content': '0.9'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '23': {'inputs': {'tag': 'api_sampler_name', 'enforce_type': 'auto', 'content': 'euler_cfg_pp'}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}, '26': {'inputs': {'scale': 6, 'adaptive_scale': 0.9, 'unet_block': 'middle', 'unet_block_id': 0, 'sigma_start': -1, 'sigma_end': -1, 'rescale': 0.5, 'rescale_mode': 'full', 'unet_block_list': '', 'model': ['15', 0]}, 'class_type': 'PerturbedAttention', '_meta': {'title': 'Perturbed-Attention Guidance (Advanced)'}}, '27': {'inputs': {'text': ['12', 0], 'token_normalization': 'length+mean', 'weight_interpretation': 'comfy++', 'clip': ['4', 1]}, 'class_type': 'BNK_CLIPTextEncodeAdvanced', '_meta': {'title': 'CLIP Text Encode (Advanced)'}}, '28': {'inputs': {'text': ['14', 0], 'token_normalization': 'length+mean', 'weight_interpretation': 'comfy++', 'clip': ['4', 1]}, 'class_type': 'BNK_CLIPTextEncodeAdvanced', '_meta': {'title': 'CLIP Text Encode (Advanced)'}}, '29': {'inputs': {'tag': 'api_steps', 'enforce_type': 'auto', 'content': 28}, 'class_type': 'TaggedAny', '_meta': {'title': 'Tagged Any'}}}\n"
     ]
    }
   ],
   "source": [
    "# Update the modifiable keys\n",
    "overrides = {'api_batchsize': '2',\n",
    " 'api_positive': 'new positive content',\n",
    " 'api_negative': 'new negative content',\n",
    " 'api_width': '896',\n",
    " 'api_height': '1152',\n",
    " 'api_cfg': '0.9',\n",
    " 'api_sampler_name': 'euler_cfg_pp',\n",
    " 'api_steps': 28\n",
    " }\n",
    "\n",
    "\n",
    "workflow.update_modifiable_keys(overrides)\n",
    "# Export the modified workflow\n",
    "exported_workflow = dict(workflow)  # or workflow.export()\n",
    "print(exported_workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Workflow with 18 nodes> | modifiable keys: ['api_batchsize', 'api_positive', 'api_negative', 'api_width', 'api_height', 'api_cfg', 'api_sampler_name', 'api_steps']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_flow.utils.run_comfy_api import WorkflowExecutor\n",
    "\n",
    "executor = WorkflowExecutor()\n",
    "res = executor.run_workflow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
